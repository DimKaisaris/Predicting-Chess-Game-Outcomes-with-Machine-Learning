{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da0176a",
   "metadata": {},
   "source": [
    "# Feature engineering. Define the train and test sets. Build two dummy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c802e563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase the width of the notebook\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359545d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc4507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_ML.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498985a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>EloDif</th>\n",
       "      <th>Opening_name</th>\n",
       "      <th>Time_format</th>\n",
       "      <th>Increment_binary</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1851</td>\n",
       "      <td>1901</td>\n",
       "      <td>-50</td>\n",
       "      <td>Alekhine's defense</td>\n",
       "      <td>classical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2060</td>\n",
       "      <td>2111</td>\n",
       "      <td>-51</td>\n",
       "      <td>French Defense</td>\n",
       "      <td>blitz</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2307</td>\n",
       "      <td>2290</td>\n",
       "      <td>17</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>blitz</td>\n",
       "      <td>No</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2380</td>\n",
       "      <td>2419</td>\n",
       "      <td>-39</td>\n",
       "      <td>Sicilian defense</td>\n",
       "      <td>rapid</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2686</td>\n",
       "      <td>2848</td>\n",
       "      <td>-162</td>\n",
       "      <td>Ruy Lopez</td>\n",
       "      <td>rapid</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WhiteElo  BlackElo  EloDif        Opening_name  Time_format  \\\n",
       "0      1851      1901     -50  Alekhine's defense   classical    \n",
       "1      2060      2111     -51      French Defense       blitz    \n",
       "2      2307      2290      17    Philidor Defense       blitz    \n",
       "3      2380      2419     -39    Sicilian defense       rapid    \n",
       "4      2686      2848    -162           Ruy Lopez       rapid    \n",
       "\n",
       "  Increment_binary  Score  \n",
       "0              Yes    1.0  \n",
       "1              Yes    0.0  \n",
       "2               No    0.5  \n",
       "3               No    0.0  \n",
       "4               No    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecfd04",
   "metadata": {},
   "source": [
    "### Given the various problems encountered during our initial model building attempts and the lack of improvement with PCA, a dedicated feature engineering phase is necessary to potentially extract more predictive information from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8216e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"BlackElo\", axis=1) #\"BlackElo\" is redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce00f3d",
   "metadata": {},
   "source": [
    "## Make Score Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da759dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'] = df['Score'].map({\n",
    "    1.0: 'White Win',\n",
    "    0.5: 'Draw',\n",
    "    0.0: 'Black Win'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcdf75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>EloDif</th>\n",
       "      <th>Opening_name</th>\n",
       "      <th>Time_format</th>\n",
       "      <th>Increment_binary</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1851</td>\n",
       "      <td>-50</td>\n",
       "      <td>Alekhine's defense</td>\n",
       "      <td>classical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>White Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2060</td>\n",
       "      <td>-51</td>\n",
       "      <td>French Defense</td>\n",
       "      <td>blitz</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Black Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2307</td>\n",
       "      <td>17</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>blitz</td>\n",
       "      <td>No</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2380</td>\n",
       "      <td>-39</td>\n",
       "      <td>Sicilian defense</td>\n",
       "      <td>rapid</td>\n",
       "      <td>No</td>\n",
       "      <td>Black Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2686</td>\n",
       "      <td>-162</td>\n",
       "      <td>Ruy Lopez</td>\n",
       "      <td>rapid</td>\n",
       "      <td>No</td>\n",
       "      <td>Black Win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WhiteElo  EloDif        Opening_name  Time_format Increment_binary  \\\n",
       "0      1851     -50  Alekhine's defense   classical               Yes   \n",
       "1      2060     -51      French Defense       blitz               Yes   \n",
       "2      2307      17    Philidor Defense       blitz                No   \n",
       "3      2380     -39    Sicilian defense       rapid                No   \n",
       "4      2686    -162           Ruy Lopez       rapid                No   \n",
       "\n",
       "       Score  \n",
       "0  White Win  \n",
       "1  Black Win  \n",
       "2       Draw  \n",
       "3  Black Win  \n",
       "4  Black Win  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415a3cd",
   "metadata": {},
   "source": [
    "### Keep the top 10 openings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae67b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_openings = df['Opening_name'].value_counts().nlargest(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4c9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all other openings into \"Other\"\n",
    "df['Opening_name'] = df['Opening_name'].where(\n",
    "    df['Opening_name'].isin(top10_openings), \n",
    "    'Other'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54df9f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                                            27530\n",
       "Sicilian defense                                 14435\n",
       "Queen's Pawn Game                                 8721\n",
       "French Defense                                    5398\n",
       "English Opening                                   5181\n",
       "Caro-Kann defense                                 3747\n",
       "Irregular Openings                                3565\n",
       "Queen's Gambit                                    3413\n",
       "Scandinavian Defense (Center-Counter Defense)     3046\n",
       "Closed Game, Irregular Responses                  2584\n",
       "Zukertort Opening                                 2380\n",
       "Name: Opening_name, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Opening_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea4f85",
   "metadata": {},
   "source": [
    "## I want to make sure that the same train and test sets will be used in all Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca51554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=10000, random_state=42,  stratify=df['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "704effd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213a366",
   "metadata": {},
   "source": [
    "## Create two dummy classification models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4895fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701292bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('Score', axis=1)\n",
    "X_test  = test.drop('Score', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9905821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Score']\n",
    "y_test  = test ['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24e2edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Most Frequent Dummy Classifier\n",
    "clf_most_frequent = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "clf_most_frequent.fit(X_train, y_train)\n",
    "y_pred_mf = clf_most_frequent.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86432daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Stratified Random Guessing Dummy Classifier\n",
    "clf_stratified = DummyClassifier(strategy='stratified', random_state=42)\n",
    "clf_stratified.fit(X_train, y_train)\n",
    "y_pred_strat = clf_stratified.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cf69195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Most Frequent Dummy Classifier ===\n",
      "Accuracy: 0.491\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Black Win       0.00      0.00      0.00      4524\n",
      "        Draw       0.00      0.00      0.00       566\n",
      "   White Win       0.49      1.00      0.66      4910\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.16      0.33      0.22     10000\n",
      "weighted avg       0.24      0.49      0.32     10000\n",
      "\n",
      "=== Stratified Dummy Classifier ===\n",
      "Accuracy: 0.4549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Black Win       0.46      0.45      0.46      4524\n",
      "        Draw       0.06      0.06      0.06       566\n",
      "   White Win       0.50      0.50      0.50      4910\n",
      "\n",
      "    accuracy                           0.45     10000\n",
      "   macro avg       0.34      0.34      0.34     10000\n",
      "weighted avg       0.45      0.45      0.45     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate both classifiers\n",
    "print(\"=== Most Frequent Dummy Classifier ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_mf))\n",
    "\n",
    "print(\"=== Stratified Dummy Classifier ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_strat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_strat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb70818",
   "metadata": {},
   "source": [
    "\n",
    "#### Most Frequent Dummy (Accuracy ≈ 0.491):\n",
    "#### By always predicting the single most common outcome in the test set, this classifier is right just under half the time. Its accuracy essentially equals the proportion of the majority class in your data.\n",
    "\n",
    "#### Stratified Dummy (Accuracy ≈ 0.4549):\n",
    "#### By randomly sampling predictions according to the empirical class frequencies, this strategy does a bit worse. It reflects the difficulty of the task: purely random draws, even when respecting label ratios, can’t beat the baseline of just guessing the most common class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb82bb5",
   "metadata": {},
   "source": [
    "## Our task is to build models that exceed these baselines—ideally pushing well above 0.49 accuracy—and also offer balanced performance across all three outcomes (white win, draw, black win)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
