{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532b2626",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11445d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase the width of the notebook\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54395d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb53ff",
   "metadata": {},
   "source": [
    "## Separate features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9261be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "y_train = train[\"Score\"]\n",
    "y_test = test[\"Score\"]\n",
    "\n",
    "X_train = train.drop(\"Score\", axis=1)\n",
    "X_test = test.drop(\"Score\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad1e00b",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d212907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing pipelines\n",
    "numeric_features = [\"WhiteElo\", \"EloDif\"]\n",
    "categorical_features = [\"Opening_name\", \"Time_format\", \"Increment_binary\"]\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70400773-6dfd-491a-b832-386d404a0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed  = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc112bbd-1069-482f-8249-b97ec24da042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1969/1969 - 8s - 4ms/step - accuracy: 0.5360 - loss: 0.8498 - val_accuracy: 0.5443 - val_loss: 0.8485\n",
      "Epoch 2/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5387 - loss: 0.8447 - val_accuracy: 0.5447 - val_loss: 0.8469\n",
      "Epoch 3/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5405 - loss: 0.8433 - val_accuracy: 0.5436 - val_loss: 0.8475\n",
      "Epoch 4/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5408 - loss: 0.8433 - val_accuracy: 0.5431 - val_loss: 0.8473\n",
      "Epoch 5/30\n",
      "1969/1969 - 4s - 2ms/step - accuracy: 0.5399 - loss: 0.8426 - val_accuracy: 0.5376 - val_loss: 0.8474\n",
      "Epoch 6/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5422 - loss: 0.8423 - val_accuracy: 0.5379 - val_loss: 0.8472\n",
      "Epoch 7/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5408 - loss: 0.8418 - val_accuracy: 0.5437 - val_loss: 0.8474\n",
      "Epoch 8/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5423 - loss: 0.8414 - val_accuracy: 0.5346 - val_loss: 0.8465\n",
      "Epoch 9/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5438 - loss: 0.8418 - val_accuracy: 0.5414 - val_loss: 0.8469\n",
      "Epoch 10/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5422 - loss: 0.8410 - val_accuracy: 0.5399 - val_loss: 0.8521\n",
      "Epoch 11/30\n",
      "1969/1969 - 3s - 2ms/step - accuracy: 0.5438 - loss: 0.8408 - val_accuracy: 0.5384 - val_loss: 0.8470\n",
      "Epoch 12/30\n",
      "1969/1969 - 3s - 1ms/step - accuracy: 0.5434 - loss: 0.8404 - val_accuracy: 0.5424 - val_loss: 0.8459\n",
      "Epoch 13/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5427 - loss: 0.8403 - val_accuracy: 0.5356 - val_loss: 0.8474\n",
      "Epoch 14/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5422 - loss: 0.8401 - val_accuracy: 0.5433 - val_loss: 0.8477\n",
      "Epoch 15/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5444 - loss: 0.8398 - val_accuracy: 0.5424 - val_loss: 0.8476\n",
      "Epoch 16/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5429 - loss: 0.8399 - val_accuracy: 0.5431 - val_loss: 0.8470\n",
      "Epoch 17/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5452 - loss: 0.8395 - val_accuracy: 0.5374 - val_loss: 0.8474\n",
      "Epoch 18/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5428 - loss: 0.8392 - val_accuracy: 0.5421 - val_loss: 0.8472\n",
      "Epoch 19/30\n",
      "1969/1969 - 3s - 1ms/step - accuracy: 0.5445 - loss: 0.8388 - val_accuracy: 0.5390 - val_loss: 0.8482\n",
      "Epoch 20/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5441 - loss: 0.8389 - val_accuracy: 0.5371 - val_loss: 0.8480\n",
      "Epoch 21/30\n",
      "1969/1969 - 4s - 2ms/step - accuracy: 0.5457 - loss: 0.8388 - val_accuracy: 0.5447 - val_loss: 0.8475\n",
      "Epoch 22/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5439 - loss: 0.8385 - val_accuracy: 0.5370 - val_loss: 0.8481\n",
      "Epoch 23/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5453 - loss: 0.8381 - val_accuracy: 0.5384 - val_loss: 0.8474\n",
      "Epoch 24/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5463 - loss: 0.8383 - val_accuracy: 0.5419 - val_loss: 0.8468\n",
      "Epoch 25/30\n",
      "1969/1969 - 3s - 1ms/step - accuracy: 0.5452 - loss: 0.8376 - val_accuracy: 0.5401 - val_loss: 0.8476\n",
      "Epoch 26/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5448 - loss: 0.8377 - val_accuracy: 0.5369 - val_loss: 0.8489\n",
      "Epoch 27/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5458 - loss: 0.8372 - val_accuracy: 0.5403 - val_loss: 0.8495\n",
      "Epoch 28/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5462 - loss: 0.8373 - val_accuracy: 0.5459 - val_loss: 0.8483\n",
      "Epoch 29/30\n",
      "1969/1969 - 3s - 1ms/step - accuracy: 0.5458 - loss: 0.8370 - val_accuracy: 0.5447 - val_loss: 0.8484\n",
      "Epoch 30/30\n",
      "1969/1969 - 2s - 1ms/step - accuracy: 0.5466 - loss: 0.8368 - val_accuracy: 0.5421 - val_loss: 0.8496\n",
      "Test accuracy (NN): 0.542\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Black Win       0.54      0.46      0.50      4524\n",
      "        Draw       0.00      0.00      0.00       566\n",
      "   White Win       0.55      0.68      0.60      4910\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.36      0.38      0.37     10000\n",
      "weighted avg       0.51      0.54      0.52     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1) Prepare dense inputs\n",
    "if hasattr(X_train_transformed, \"toarray\"):\n",
    "    X_train_nn = X_train_transformed.toarray()\n",
    "    X_test_nn  = X_test_transformed.toarray()\n",
    "else:\n",
    "    X_train_nn = X_train_transformed\n",
    "    X_test_nn  = X_test_transformed\n",
    "\n",
    "# 2) Encode string labels as integers, then one‑hot\n",
    "le = LabelEncoder()\n",
    "y_train_int = le.fit_transform(y_train)\n",
    "y_test_int  = le.transform(y_test)\n",
    "y_train_cat = to_categorical(y_train_int)\n",
    "y_test_cat  = to_categorical(y_test_int)\n",
    "\n",
    "# 3) Build a simple MLP\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_nn.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(y_train_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 4) Train\n",
    "history = model.fit(\n",
    "    X_train_nn, y_train_cat,\n",
    "    validation_split=0.1,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 5) Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(X_test_nn, y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy (NN): {test_acc:.3f}\")\n",
    "\n",
    "# 6) Detailed classification report\n",
    "y_pred_probs = model.predict(X_test_nn)\n",
    "y_pred_int   = np.argmax(y_pred_probs, axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_int, y_pred_int, target_names=le.classes_))\n",
    "\n",
    "# 7) Save the model\n",
    "model.save('simple_mlp_chess.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3894e",
   "metadata": {},
   "source": [
    "### Even a neural network model was unable to exceed the 54% accuracy barrier, achieving a performance similar to our best traditional models like Random Forest, AdaBoost, and Gradient Boosting.\n",
    "### This  suggests that the limitations might be more fundamental to the data itself or the inherent predictability of the task, rather than just the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6462ca2",
   "metadata": {},
   "source": [
    "## Deeper Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14532ad0-2dbe-4008-922a-25cf45b9aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0cf76b-25b0-484c-8f0a-6114ed8c45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985/985 - 5s - 5ms/step - accuracy: 0.5011 - loss: 0.9639 - val_accuracy: 0.5370 - val_loss: 0.8488\n",
      "Epoch 2/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5343 - loss: 0.8591 - val_accuracy: 0.5313 - val_loss: 0.8495\n",
      "Epoch 3/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5350 - loss: 0.8526 - val_accuracy: 0.5357 - val_loss: 0.8471\n",
      "Epoch 4/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5371 - loss: 0.8512 - val_accuracy: 0.5403 - val_loss: 0.8484\n",
      "Epoch 5/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5352 - loss: 0.8503 - val_accuracy: 0.5450 - val_loss: 0.8468\n",
      "Epoch 6/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5348 - loss: 0.8489 - val_accuracy: 0.5443 - val_loss: 0.8462\n",
      "Epoch 7/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5363 - loss: 0.8486 - val_accuracy: 0.5413 - val_loss: 0.8476\n",
      "Epoch 8/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5363 - loss: 0.8479 - val_accuracy: 0.5441 - val_loss: 0.8484\n",
      "Epoch 9/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5348 - loss: 0.8472 - val_accuracy: 0.5373 - val_loss: 0.8468\n",
      "Epoch 10/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5362 - loss: 0.8470 - val_accuracy: 0.5416 - val_loss: 0.8471\n",
      "Epoch 11/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5367 - loss: 0.8468 - val_accuracy: 0.5447 - val_loss: 0.8461\n",
      "Epoch 12/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5384 - loss: 0.8463 - val_accuracy: 0.5447 - val_loss: 0.8469\n",
      "Epoch 13/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5365 - loss: 0.8458 - val_accuracy: 0.5487 - val_loss: 0.8468\n",
      "Epoch 14/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5401 - loss: 0.8465 - val_accuracy: 0.5451 - val_loss: 0.8452\n",
      "Epoch 15/100\n",
      "985/985 - 2s - 3ms/step - accuracy: 0.5371 - loss: 0.8458 - val_accuracy: 0.5371 - val_loss: 0.8483\n",
      "Epoch 16/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5374 - loss: 0.8462 - val_accuracy: 0.5483 - val_loss: 0.8456\n",
      "Epoch 17/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5376 - loss: 0.8455 - val_accuracy: 0.5424 - val_loss: 0.8465\n",
      "Epoch 18/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5392 - loss: 0.8452 - val_accuracy: 0.5403 - val_loss: 0.8469\n",
      "Epoch 19/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5404 - loss: 0.8444 - val_accuracy: 0.5387 - val_loss: 0.8460\n",
      "Epoch 20/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5420 - loss: 0.8451 - val_accuracy: 0.5449 - val_loss: 0.8460\n",
      "Epoch 21/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5377 - loss: 0.8446 - val_accuracy: 0.5416 - val_loss: 0.8462\n",
      "Epoch 22/100\n",
      "985/985 - 2s - 2ms/step - accuracy: 0.5391 - loss: 0.8446 - val_accuracy: 0.5416 - val_loss: 0.8459\n",
      "Test accuracy (deep MLP): 0.544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a deeper network\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_nn.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(y_train_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for early stopping + best‑model checkpointing\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_mlp_dropout.keras', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train_nn, y_train_cat,\n",
    "    validation_split=0.1,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test_nn, y_test_cat, verbose=0)\n",
    "print(\"Test accuracy (deep MLP):\", round(test_acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ea76c",
   "metadata": {},
   "source": [
    "### By incorporating Dropout and Batch Normalization, we were able to slightly enhance our neural network's performance, reaching an accuracy of 0.544."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
